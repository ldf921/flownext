optimizer:
  learning_rate:
    - [200000.0, 5.0e-4]
    - [600000.0, 1.0e-4]
    - [800000.0, 5.0e-5]
  params:
    wd:
      0.0
  lr_mult:
    1.0
  type:
    adam

network:
  class:
    Spynet
  scale:
    16
  activation:
    typename:
      nn.LeakyReLU
    args:
      - 0.1
    
loss:
  scales:
    - 16
  match:
    upsampling